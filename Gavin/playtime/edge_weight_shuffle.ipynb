{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Weight Shuffle\n",
    "\n",
    "Adam has the cool idea for a null model to shuffle the edge weights that we filter on to test whether the observed persistence diagram is a result of the shape of the network or the specific combination of shape and filtration parameter. We implement that here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some packages\n",
    "import Gavin.utils.random_complexes as rc\n",
    "import Gavin.utils.make_network as mn\n",
    "from time import time\n",
    "import oatpy as oat\n",
    "\n",
    "# config\n",
    "DATA_PATH = 'datasets/concept_network/'\n",
    "CONCEPT_FILE = 'articles_category_for_2l_abstracts_concepts_processed_v1_EX_102.csv.gz' # Applied Mathematics\n",
    "# CONCEPT_FILE = 'concepts_Applied Economics_1402.csv.gz' # Applied Econ\n",
    "# CONCEPT_FILE = 'concepts_Zoology_608.csv' # Zoology\n",
    "MIN_RELEVANCE= 0.7\n",
    "MIN_FREQ = 0.00006 # 0.006%\n",
    "MAX_FREQ = 0.0005 # 0.05%\n",
    "MIN_YEAR = 1920"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Network\n",
    "Use the data file to create the original network and calculate homology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the network\n",
    "G_orig = mn.gen_concept_network(\n",
    "        DATA_PATH + CONCEPT_FILE,\n",
    "        min_relevance=MIN_RELEVANCE,\n",
    "        min_year=MIN_YEAR,\n",
    "        min_articles=MIN_FREQ,\n",
    "        max_articles=MAX_FREQ,\n",
    "        normalize_year=True\n",
    "    )\n",
    "adj_orig = mn.adj_matrix(G_orig, 'norm_year', True, 0.) # fill in diagnal with 0s since the shuffled version likley won't work without that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homology calculation\n",
    "start = time()\n",
    "\n",
    "# setup the problem\n",
    "factored_orig = oat.rust.FactoredBoundaryMatrixVr( # two functions that do this, idk what the other one is\n",
    "        dissimilarity_matrix=adj_orig,\n",
    "        homology_dimension_max=2\n",
    "    )\n",
    "\n",
    "# solve homology\n",
    "homology_orig = factored_orig.homology( # solve homology\n",
    "        return_cycle_representatives=True, # These need to be true to be able to make a barcode, makes the problem take ~30% longer (1:30ish)\n",
    "        return_bounding_chains=True\n",
    "    )\n",
    "\n",
    "f'Homology calculation took {time() - start} secs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persistance diagram\n",
    "fig = oat.plot.pd(homology_orig)\n",
    "fig.update_layout(\n",
    "        width=600, \n",
    "        height=500,\n",
    "        margin=dict(l=20, r=20, t=20, b=20)\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barcode diagram\n",
    "fig = oat.plot.barcode(homology_orig)\n",
    "fig.update_layout(\n",
    "        width=1000, \n",
    "        height=500,\n",
    "        margin=dict(l=20, r=20, t=20, b=20)\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffled Network\n",
    "Shuffle the edge weights and, again, calculate homology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the network\n",
    "G_shuffled = rc.shuffle_edge_weights(G_orig, seed=10)\n",
    "adj_shuffled = mn.adj_matrix(G_shuffled, 'norm_year', True, 0.)\n",
    "\n",
    "assert adj_orig.shape == adj_shuffled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homology calculation\n",
    "start = time()\n",
    "\n",
    "# setup the problem\n",
    "factored_shuffled = oat.rust.FactoredBoundaryMatrixVr( # two functions that do this, idk what the other one is\n",
    "        dissimilarity_matrix=adj_shuffled,\n",
    "        homology_dimension_max=2\n",
    "    )\n",
    "\n",
    "# solve homology\n",
    "homology_shuffled = factored_shuffled.homology( # solve homology\n",
    "        return_cycle_representatives=True, # These need to be true to be able to make a barcode, makes the problem take ~30% longer (1:30ish)\n",
    "        return_bounding_chains=True\n",
    "    )\n",
    "\n",
    "f'Homology calculation took {time() - start} secs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persistance diagram\n",
    "fig = oat.plot.pd(homology_shuffled)\n",
    "fig.update_layout(\n",
    "        width=600, \n",
    "        height=500,\n",
    "        margin=dict(l=20, r=20, t=20, b=20)\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barcode diagram\n",
    "fig = oat.plot.barcode(homology_shuffled)\n",
    "fig.update_layout(\n",
    "        width=1000, \n",
    "        height=500,\n",
    "        margin=dict(l=20, r=20, t=20, b=20)\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "We see our null model has a very different structure than our real network. Most obviously, it has substantially more features. The original network has 56,237 total features (9,553 dim 0; 36,112 dim 1; 10,572 dim 2) while the shuffled network has 88,068 total features (9,553 dim 0; 63,171 dim 1; 15,344 dim 2). That's more than 50% more features, including almost double the number of dimension 1 features. These features tend to be born later, especially at higher dimensions (the earliest dim 1 feature in the shuffled network is 0.1 later than the easrliest dim 1 features in the regular network), so this pattern might stop as we look at higher dimensional features. A higher percentage of the features die, although this is likley because the same features should exist at the end of both networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homology_orig[['dimension', 'birth', 'death']].groupby('dimension').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homology_shuffled[['dimension', 'birth', 'death']].groupby('dimension').describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
